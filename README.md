# EasyRead Prototype

A UNICEF Office of Innovation prototype application that explores the use of Large Language Models to convert complex documents into accessible "Easy Read" format with simplified text and relevant images. The goal of this prototype is to explore the use of Large Language Models and the necessary infrastructure to support an application aiming at creating Easy Read content. It does not aim to follow strict guidelines.

## Disclaimer

**This is a prototype created by the UNICEF Office of Innovation for evaluation purposes only.**

This repository contains an experimental prototype. It is designed for exploration and learning purposes only. It is not intended for use in UNICEF programs or by program partners without further validation and testing. The code and applications in this repository are NOT production-ready and should not be deployed in any real-world use case. They may contain bugs, security vulnerabilities, or incomplete features. The content generated by this application uses Artificial Intelligence and will contain errors, inaccuracies, or biases. 

## Overview

EasyRead uses Large Language Models (LLMs) to process complex content, generate simplified content, and match sentences with appropriate images through vector similarity search. It applies a 4 step process:

1. Create a set of Easy Read sentences and accompanying image descriptors;
2. Review the output, flagging missing and inconsistent content;
3. Use the revision to generate a new set of sentences and image descriptors;
4. Use the image descriptors to match stored images using embedding similarity.

## Key Features

- PDF to accessible format conversion using AI
- Automated image selection from symbol libraries
- Content revision and editing capabilities
- DOCX export

## Technology Stack

- **Backend**: Django REST API, PostgreSQL with pgvector extension
- **Frontend**: React + Vite, Material-UI
- **AI Services**: OpenAI, Cohere, AWS Bedrock (via LiteLLM)
- **Deployment**: Docker Compose

## Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- PostgreSQL 15+ with pgvector extension
- API keys: OpenAI, Cohere, or AWS Bedrock

### Installation

1. Clone the repository
2. Copy `.env.example` to `.env` and configure:
   - Database credentials
   - AI provider API keys
   - CORS and security settings

3. Start with Docker:
```bash
docker-compose up -d
```

4. Or run locally:
```bash
# Backend
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python manage.py migrate
python manage.py runserver

# Frontend
cd frontend
npm install
npm run dev
```

## Configuration Required

You must provide your own:
- **API Keys**: OpenAI, Cohere, or AWS Bedrock credentials
- **Database**: PostgreSQL with pgvector (SQLite not supported)
- **Image Library**: GlobalSymbols images or your own symbol set
- **Django Secret Key**: Generate a secure key for production

See `CLAUDE.md` for detailed setup and deployment instructions.

## Image Attribution

Symbols support kindly provided by [GlobalSymbols](https://www.globalsymbols.com) - making communication accessible worldwide.

## License

To be disclosed.

## Contact

For questions or security concerns: rmatsumura@unicef.org

---

**Developed by**: UNICEF Office of Innovation
**Repository**: https://github.com/UNICEF-Ventures/easyRead
